{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb9f6e2e",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbad8090-72c1-4f3e-a156-c5df67bb8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python inference.py \\\n",
    "  --output outdir/results.jsonl \\\n",
    "  --langs python,java \\\n",
    "  --cache_dir humaneval_cache \\\n",
    "  --host localhost \\\n",
    "  --model /models/qwen2 \\\n",
    "  --max_tokens 512 \\\n",
    "  --temperature 0.2 \\\n",
    "  --timeout 2000 \\\n",
    "  --ports 8001,8002,8003,8004,8005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbf5db9-5b5e-42f5-8b12-5e49746fb42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "python inference-multi.py \n",
    "--output outdir/results.jsonl \n",
    "--langs python,java \n",
    "--cache_dir humaneval_cache \n",
    "--cpu-cores 60 \n",
    "--instances 20 \n",
    "--base-port 8010 \n",
    "--concurrency 1 \n",
    "--model /models/qwen2 \n",
    "--pass-k 2 \n",
    "--repeat 2 \n",
    "--timeout 4000 \n",
    "--resume True "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b80d051",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b5a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker run --rm -it --gpus all `\n",
    "  --mount type=bind,source=\"$(pwd)/CodeGeeX\",target=\"/workspace/CodeGeeX\" `\n",
    "  --mount type=bind,source=\"$(pwd)/outdir\",target=\"/workspace/CodeGeeX/results\" `\n",
    "  rishubi/codegeex:latest `\n",
    "  bash -c \"cd /workspace/CodeGeeX && `\n",
    "    bash scripts/evaluate_humaneval_x.sh results/results_python.jsonl python 4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f65a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# 这里会把整个仓库下载到本地目录 `./Qwen2.5-Coder-0.5B-Instruct/`\n",
    "local_dir = snapshot_download(\n",
    "    repo_id=\"Qwen/Qwen2.5-Coder-0.5B-Instruct\",\n",
    "    repo_type=\"model\",        # 明确指定这是 model repo\n",
    "    cache_dir=\"./models_cache\",  # 可选：自定义缓存目录\n",
    "    local_dir=\"./Qwen2.5-Coder-0.5B-Instruct\",  # 也可以不指定，用 HF 缓存\n",
    "    resume_download=True       # 若中断可续传\n",
    ")\n",
    "\n",
    "print(\"Downloaded to:\", local_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b3ca07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ 每个实例分配 2 线程\n",
      "[!] 移除已存在容器 vllm_cpu_8010\n",
      "[*] 启动容器 vllm_cpu_8010，映射端口 8010 → 8000 …\n",
      "[✓] vllm_cpu_8010 启动成功！\n",
      "[!] 移除已存在容器 vllm_cpu_8011\n",
      "[*] 启动容器 vllm_cpu_8011，映射端口 8011 → 8000 …\n",
      "[✓] vllm_cpu_8011 启动成功！\n",
      "[!] 移除已存在容器 vllm_cpu_8012\n",
      "[*] 启动容器 vllm_cpu_8012，映射端口 8012 → 8000 …\n",
      "[✓] vllm_cpu_8012 启动成功！\n",
      "[!] 移除已存在容器 vllm_cpu_8013\n",
      "[*] 启动容器 vllm_cpu_8013，映射端口 8013 → 8000 …\n",
      "[✓] vllm_cpu_8013 启动成功！\n",
      "[*] 启动容器 vllm_cpu_8014，映射端口 8014 → 8000 …\n",
      "[✓] vllm_cpu_8014 启动成功！\n",
      "[*] 启动容器 vllm_cpu_8015，映射端口 8015 → 8000 …\n",
      "[✓] vllm_cpu_8015 启动成功！\n",
      "[*] 启动容器 vllm_cpu_8016，映射端口 8016 → 8000 …\n",
      "[✓] vllm_cpu_8016 启动成功！\n",
      "[*] 启动容器 vllm_cpu_8017，映射端口 8017 → 8000 …\n",
      "[✓] vllm_cpu_8017 启动成功！\n",
      "[*] 等待 120 秒，确保所有服务启动完毕…\n",
      "→ 并发请求分配: [2, 2, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "🚀 并发 10 次，总耗时 192.49s，平均 19.25s/次\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# filename: benchmark_qwen2_auto_cleanup.py\n",
    "\n",
    "import time\n",
    "import docker\n",
    "import requests\n",
    "import concurrent.futures\n",
    "from docker.errors import NotFound, APIError\n",
    "\n",
    "# —— 配置区 —— \n",
    "IMAGE                = \"konstantinvernermaif/vllm-cpu:latest\"\n",
    "HOST_MODEL_PATH      = r\"D:\\subway\\project\\qwen-serve\\Qwen2.5-Coder-0.5B-Instruct\"\n",
    "CONTAINER_MODEL_PATH = \"/models/qwen2\"\n",
    "\n",
    "TOTAL_CPU_CORES      = 16     # 宿主机总 CPU 核心数\n",
    "INSTANCE_COUNT       = 4      # Docker 实例数量\n",
    "BASE_PORT            = 8010   # 第一个实例映射端口，依次 +1\n",
    "\n",
    "TOTAL_REQUESTS       = 10     # 总并发请求数\n",
    "PROMPT               = \"San Francisco is a\"\n",
    "\n",
    "\n",
    "def start_containers():\n",
    "    threads_per_instance = TOTAL_CPU_CORES // INSTANCE_COUNT\n",
    "    env_threads = str(threads_per_instance)\n",
    "    client = docker.from_env()\n",
    "\n",
    "    print(f\"→ 每个实例分配 {threads_per_instance} 线程\")\n",
    "\n",
    "    for i in range(INSTANCE_COUNT):\n",
    "        name = f\"vllm_cpu_{BASE_PORT + i}\"\n",
    "        port = BASE_PORT + i\n",
    "\n",
    "        # 清理旧容器\n",
    "        try:\n",
    "            old = client.containers.get(name)\n",
    "            print(f\"[!] 移除已存在容器 {name}\")\n",
    "            old.remove(force=True)\n",
    "        except NotFound:\n",
    "            pass\n",
    "\n",
    "        print(f\"[*] 启动容器 {name}，映射端口 {port} → 8000 …\")\n",
    "        try:\n",
    "            client.containers.run(\n",
    "                image=IMAGE,\n",
    "                name=name,\n",
    "                detach=True,\n",
    "                environment={\n",
    "                    \"OMP_NUM_THREADS\": env_threads,\n",
    "                    \"MKL_NUM_THREADS\": env_threads\n",
    "                },\n",
    "                restart_policy={\"Name\": \"unless-stopped\"},\n",
    "                ipc_mode=\"host\",\n",
    "                volumes={HOST_MODEL_PATH: {\"bind\": CONTAINER_MODEL_PATH, \"mode\": \"ro\"}},\n",
    "                ports={\"8000/tcp\": port},\n",
    "                command=[\n",
    "                    \"--model\", CONTAINER_MODEL_PATH,\n",
    "                    \"--host\", \"0.0.0.0\",\n",
    "                    \"--port\", \"8000\"\n",
    "                ]\n",
    "            )\n",
    "            print(f\"[✓] {name} 启动成功！\")\n",
    "        except APIError as e:\n",
    "            print(f\"[✗] 启动 {name} 失败：{e.explanation}\")\n",
    "            exit(1)\n",
    "\n",
    "    print(\"[*] 等待 120 秒，确保所有服务启动完毕…\")\n",
    "    time.sleep(120)\n",
    "\n",
    "\n",
    "def call_instance(port: int, prompt: str):\n",
    "    url = f\"http://localhost:{port}/v1/completions\"\n",
    "    payload = {\n",
    "        \"model\": CONTAINER_MODEL_PATH,\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 100,\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "    resp = requests.post(url, json=payload, headers={\"Content-Type\": \"application/json\"})\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"choices\"][0][\"text\"]\n",
    "\n",
    "\n",
    "def benchmark_all():\n",
    "    # 计算 per-instance 的并发数分配\n",
    "    base = TOTAL_REQUESTS // INSTANCE_COUNT\n",
    "    rem = TOTAL_REQUESTS % INSTANCE_COUNT\n",
    "    concurrencies = [base + (1 if i < rem else 0) for i in range(INSTANCE_COUNT)]\n",
    "    print(f\"→ 并发请求分配: {concurrencies}\")\n",
    "\n",
    "    # 构造所有 (port, prompt) 任务\n",
    "    tasks = []\n",
    "    for idx, port in enumerate(range(BASE_PORT, BASE_PORT + INSTANCE_COUNT)):\n",
    "        tasks += [(port, PROMPT)] * concurrencies[idx]\n",
    "\n",
    "    # 一次性并发提交\n",
    "    total_start = time.perf_counter()\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=TOTAL_REQUESTS) as pool:\n",
    "        futures = [pool.submit(call_instance, port, prompt) for port, prompt in tasks]\n",
    "        for f in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                _ = f.result()\n",
    "            except Exception as e:\n",
    "                print(\"[✗] 请求出错：\", e)\n",
    "    total_elapsed = time.perf_counter() - total_start\n",
    "\n",
    "    print(f\"\\n🚀 并发 {TOTAL_REQUESTS} 次，总耗时 {total_elapsed:.2f}s，\"\n",
    "          f\"平均 {total_elapsed/TOTAL_REQUESTS:.2f}s/次\")\n",
    "\n",
    "\n",
    "def stop_containers():\n",
    "    client = docker.from_env()\n",
    "    for i in range(INSTANCE_COUNT):\n",
    "        name = f\"vllm_cpu_{BASE_PORT + i}\"\n",
    "        try:\n",
    "            cont = client.containers.get(name)\n",
    "            cont.remove(force=True)\n",
    "            print(f\"[✓] 已移除容器 {name}\")\n",
    "        except NotFound:\n",
    "            print(f\"[!] 容器 {name} 不存在或已被移除\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        start_containers()\n",
    "        benchmark_all()\n",
    "    finally:\n",
    "        print(\"\\n[*] 清理：停止并移除所有容器…\")\n",
    "        stop_containers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f538f3c6-20b1-4b4e-a2fa-8580efea9d26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        return number % 1.0;\n"
     ]
    }
   ],
   "source": [
    "def extract_indented_body(code: str) -> str:\n",
    "    \"\"\"提取 Python 或 Java 的代码主体\"\"\"\n",
    "    lines = code.splitlines()\n",
    "    # Python 函数体提取\n",
    "    if any(ln.startswith(\"def \") for ln in lines):\n",
    "        saw = False\n",
    "        out = []\n",
    "        for ln in lines:\n",
    "            if not saw:\n",
    "                if ln.startswith(\"def \"):\n",
    "                    saw = True\n",
    "                continue\n",
    "            out.append(ln)\n",
    "        return \"\\n\".join(out).rstrip()\n",
    "    # Java 方法体提取\n",
    "    if any(ln.strip().startswith((\"public \", \"private \", \"protected \")) for ln in lines):\n",
    "        start_idx = None\n",
    "        # 寻找方法签名后的第一行 '{' 之后的内容\n",
    "        for i, ln in enumerate(lines):\n",
    "            if \"{\" in ln:\n",
    "                start_idx = i + 1\n",
    "                break\n",
    "        # 寻找最后一个 '}' 的行\n",
    "        end_idx = None\n",
    "        for j in range(len(lines) - 1, -1, -1):\n",
    "            if \"}\" in lines[j]:\n",
    "                end_idx = j\n",
    "                break\n",
    "        if start_idx is not None and end_idx is not None and start_idx < end_idx:\n",
    "            return \"\\n\".join(lines[start_idx:end_idx]).rstrip()\n",
    "    # 默认按缩进提取\n",
    "    return \"\\n\".join([ln for ln in lines if ln.startswith(\"    \") or ln.startswith(\"\\t\")]).rstrip()\n",
    "# ------------------------ 测试 extract_indented_body ------------------------ #\n",
    "def test_extract_java():\n",
    "    java_code = \"        return number % 1.0;\"\n",
    "    body = extract_indented_body(java_code)\n",
    "    if \") {\\n\" in body:\n",
    "        print(\"Java code detected, extracting method body...\")\n",
    "        body = extract_indented_body(body)\n",
    "    print(body)\n",
    "test_extract_java()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda] *",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
