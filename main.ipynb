{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb9f6e2e",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbad8090-72c1-4f3e-a156-c5df67bb8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python inference.py \\\n",
    "  --output outdir/results.jsonl \\\n",
    "  --langs python,java \\\n",
    "  --cache_dir humaneval_cache \\\n",
    "  --host localhost \\\n",
    "  --model /models/qwen2 \\\n",
    "  --max_tokens 512 \\\n",
    "  --temperature 0.2 \\\n",
    "  --timeout 2000 \\\n",
    "  --ports 8001,8002,8003,8004,8005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbf5db9-5b5e-42f5-8b12-5e49746fb42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "python inference-multi.py \n",
    "--output outdir/results.jsonl \n",
    "--langs python,java \n",
    "--cache_dir humaneval_cache \n",
    "--cpu-cores 60 \n",
    "--instances 20 \n",
    "--base-port 8010 \n",
    "--concurrency 1 \n",
    "--model /models/qwen2 \n",
    "--pass-k 2 \n",
    "--repeat 2 \n",
    "--timeout 4000 \n",
    "--resume True "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b80d051",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b5a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker run --rm -it --gpus all `\n",
    "  --mount type=bind,source=\"$(pwd)/CodeGeeX\",target=\"/workspace/CodeGeeX\" `\n",
    "  --mount type=bind,source=\"$(pwd)/outdir\",target=\"/workspace/CodeGeeX/results\" `\n",
    "  rishubi/codegeex:latest `\n",
    "  bash -c \"cd /workspace/CodeGeeX && `\n",
    "    bash scripts/evaluate_humaneval_x.sh results/results_python.jsonl python 4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f65a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# è¿™é‡Œä¼šæŠŠæ•´ä¸ªä»“åº“ä¸‹è½½åˆ°æœ¬åœ°ç›®å½• `./Qwen2.5-Coder-0.5B-Instruct/`\n",
    "local_dir = snapshot_download(\n",
    "    repo_id=\"Qwen/Qwen2.5-Coder-0.5B-Instruct\",\n",
    "    repo_type=\"model\",        # æ˜ç¡®æŒ‡å®šè¿™æ˜¯ model repo\n",
    "    cache_dir=\"./models_cache\",  # å¯é€‰ï¼šè‡ªå®šä¹‰ç¼“å­˜ç›®å½•\n",
    "    local_dir=\"./Qwen2.5-Coder-0.5B-Instruct\",  # ä¹Ÿå¯ä»¥ä¸æŒ‡å®šï¼Œç”¨ HF ç¼“å­˜\n",
    "    resume_download=True       # è‹¥ä¸­æ–­å¯ç»­ä¼ \n",
    ")\n",
    "\n",
    "print(\"Downloaded to:\", local_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b3ca07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â†’ æ¯ä¸ªå®ä¾‹åˆ†é… 2 çº¿ç¨‹\n",
      "[!] ç§»é™¤å·²å­˜åœ¨å®¹å™¨ vllm_cpu_8010\n",
      "[*] å¯åŠ¨å®¹å™¨ vllm_cpu_8010ï¼Œæ˜ å°„ç«¯å£ 8010 â†’ 8000 â€¦\n",
      "[âœ“] vllm_cpu_8010 å¯åŠ¨æˆåŠŸï¼\n",
      "[!] ç§»é™¤å·²å­˜åœ¨å®¹å™¨ vllm_cpu_8011\n",
      "[*] å¯åŠ¨å®¹å™¨ vllm_cpu_8011ï¼Œæ˜ å°„ç«¯å£ 8011 â†’ 8000 â€¦\n",
      "[âœ“] vllm_cpu_8011 å¯åŠ¨æˆåŠŸï¼\n",
      "[!] ç§»é™¤å·²å­˜åœ¨å®¹å™¨ vllm_cpu_8012\n",
      "[*] å¯åŠ¨å®¹å™¨ vllm_cpu_8012ï¼Œæ˜ å°„ç«¯å£ 8012 â†’ 8000 â€¦\n",
      "[âœ“] vllm_cpu_8012 å¯åŠ¨æˆåŠŸï¼\n",
      "[!] ç§»é™¤å·²å­˜åœ¨å®¹å™¨ vllm_cpu_8013\n",
      "[*] å¯åŠ¨å®¹å™¨ vllm_cpu_8013ï¼Œæ˜ å°„ç«¯å£ 8013 â†’ 8000 â€¦\n",
      "[âœ“] vllm_cpu_8013 å¯åŠ¨æˆåŠŸï¼\n",
      "[*] å¯åŠ¨å®¹å™¨ vllm_cpu_8014ï¼Œæ˜ å°„ç«¯å£ 8014 â†’ 8000 â€¦\n",
      "[âœ“] vllm_cpu_8014 å¯åŠ¨æˆåŠŸï¼\n",
      "[*] å¯åŠ¨å®¹å™¨ vllm_cpu_8015ï¼Œæ˜ å°„ç«¯å£ 8015 â†’ 8000 â€¦\n",
      "[âœ“] vllm_cpu_8015 å¯åŠ¨æˆåŠŸï¼\n",
      "[*] å¯åŠ¨å®¹å™¨ vllm_cpu_8016ï¼Œæ˜ å°„ç«¯å£ 8016 â†’ 8000 â€¦\n",
      "[âœ“] vllm_cpu_8016 å¯åŠ¨æˆåŠŸï¼\n",
      "[*] å¯åŠ¨å®¹å™¨ vllm_cpu_8017ï¼Œæ˜ å°„ç«¯å£ 8017 â†’ 8000 â€¦\n",
      "[âœ“] vllm_cpu_8017 å¯åŠ¨æˆåŠŸï¼\n",
      "[*] ç­‰å¾… 120 ç§’ï¼Œç¡®ä¿æ‰€æœ‰æœåŠ¡å¯åŠ¨å®Œæ¯•â€¦\n",
      "â†’ å¹¶å‘è¯·æ±‚åˆ†é…: [2, 2, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "ğŸš€ å¹¶å‘ 10 æ¬¡ï¼Œæ€»è€—æ—¶ 192.49sï¼Œå¹³å‡ 19.25s/æ¬¡\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# filename: benchmark_qwen2_auto_cleanup.py\n",
    "\n",
    "import time\n",
    "import docker\n",
    "import requests\n",
    "import concurrent.futures\n",
    "from docker.errors import NotFound, APIError\n",
    "\n",
    "# â€”â€” é…ç½®åŒº â€”â€” \n",
    "IMAGE                = \"konstantinvernermaif/vllm-cpu:latest\"\n",
    "HOST_MODEL_PATH      = r\"D:\\subway\\project\\qwen-serve\\Qwen2.5-Coder-0.5B-Instruct\"\n",
    "CONTAINER_MODEL_PATH = \"/models/qwen2\"\n",
    "\n",
    "TOTAL_CPU_CORES      = 16     # å®¿ä¸»æœºæ€» CPU æ ¸å¿ƒæ•°\n",
    "INSTANCE_COUNT       = 4      # Docker å®ä¾‹æ•°é‡\n",
    "BASE_PORT            = 8010   # ç¬¬ä¸€ä¸ªå®ä¾‹æ˜ å°„ç«¯å£ï¼Œä¾æ¬¡ +1\n",
    "\n",
    "TOTAL_REQUESTS       = 10     # æ€»å¹¶å‘è¯·æ±‚æ•°\n",
    "PROMPT               = \"San Francisco is a\"\n",
    "\n",
    "\n",
    "def start_containers():\n",
    "    threads_per_instance = TOTAL_CPU_CORES // INSTANCE_COUNT\n",
    "    env_threads = str(threads_per_instance)\n",
    "    client = docker.from_env()\n",
    "\n",
    "    print(f\"â†’ æ¯ä¸ªå®ä¾‹åˆ†é… {threads_per_instance} çº¿ç¨‹\")\n",
    "\n",
    "    for i in range(INSTANCE_COUNT):\n",
    "        name = f\"vllm_cpu_{BASE_PORT + i}\"\n",
    "        port = BASE_PORT + i\n",
    "\n",
    "        # æ¸…ç†æ—§å®¹å™¨\n",
    "        try:\n",
    "            old = client.containers.get(name)\n",
    "            print(f\"[!] ç§»é™¤å·²å­˜åœ¨å®¹å™¨ {name}\")\n",
    "            old.remove(force=True)\n",
    "        except NotFound:\n",
    "            pass\n",
    "\n",
    "        print(f\"[*] å¯åŠ¨å®¹å™¨ {name}ï¼Œæ˜ å°„ç«¯å£ {port} â†’ 8000 â€¦\")\n",
    "        try:\n",
    "            client.containers.run(\n",
    "                image=IMAGE,\n",
    "                name=name,\n",
    "                detach=True,\n",
    "                environment={\n",
    "                    \"OMP_NUM_THREADS\": env_threads,\n",
    "                    \"MKL_NUM_THREADS\": env_threads\n",
    "                },\n",
    "                restart_policy={\"Name\": \"unless-stopped\"},\n",
    "                ipc_mode=\"host\",\n",
    "                volumes={HOST_MODEL_PATH: {\"bind\": CONTAINER_MODEL_PATH, \"mode\": \"ro\"}},\n",
    "                ports={\"8000/tcp\": port},\n",
    "                command=[\n",
    "                    \"--model\", CONTAINER_MODEL_PATH,\n",
    "                    \"--host\", \"0.0.0.0\",\n",
    "                    \"--port\", \"8000\"\n",
    "                ]\n",
    "            )\n",
    "            print(f\"[âœ“] {name} å¯åŠ¨æˆåŠŸï¼\")\n",
    "        except APIError as e:\n",
    "            print(f\"[âœ—] å¯åŠ¨ {name} å¤±è´¥ï¼š{e.explanation}\")\n",
    "            exit(1)\n",
    "\n",
    "    print(\"[*] ç­‰å¾… 120 ç§’ï¼Œç¡®ä¿æ‰€æœ‰æœåŠ¡å¯åŠ¨å®Œæ¯•â€¦\")\n",
    "    time.sleep(120)\n",
    "\n",
    "\n",
    "def call_instance(port: int, prompt: str):\n",
    "    url = f\"http://localhost:{port}/v1/completions\"\n",
    "    payload = {\n",
    "        \"model\": CONTAINER_MODEL_PATH,\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 100,\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "    resp = requests.post(url, json=payload, headers={\"Content-Type\": \"application/json\"})\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"choices\"][0][\"text\"]\n",
    "\n",
    "\n",
    "def benchmark_all():\n",
    "    # è®¡ç®— per-instance çš„å¹¶å‘æ•°åˆ†é…\n",
    "    base = TOTAL_REQUESTS // INSTANCE_COUNT\n",
    "    rem = TOTAL_REQUESTS % INSTANCE_COUNT\n",
    "    concurrencies = [base + (1 if i < rem else 0) for i in range(INSTANCE_COUNT)]\n",
    "    print(f\"â†’ å¹¶å‘è¯·æ±‚åˆ†é…: {concurrencies}\")\n",
    "\n",
    "    # æ„é€ æ‰€æœ‰ (port, prompt) ä»»åŠ¡\n",
    "    tasks = []\n",
    "    for idx, port in enumerate(range(BASE_PORT, BASE_PORT + INSTANCE_COUNT)):\n",
    "        tasks += [(port, PROMPT)] * concurrencies[idx]\n",
    "\n",
    "    # ä¸€æ¬¡æ€§å¹¶å‘æäº¤\n",
    "    total_start = time.perf_counter()\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=TOTAL_REQUESTS) as pool:\n",
    "        futures = [pool.submit(call_instance, port, prompt) for port, prompt in tasks]\n",
    "        for f in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                _ = f.result()\n",
    "            except Exception as e:\n",
    "                print(\"[âœ—] è¯·æ±‚å‡ºé”™ï¼š\", e)\n",
    "    total_elapsed = time.perf_counter() - total_start\n",
    "\n",
    "    print(f\"\\nğŸš€ å¹¶å‘ {TOTAL_REQUESTS} æ¬¡ï¼Œæ€»è€—æ—¶ {total_elapsed:.2f}sï¼Œ\"\n",
    "          f\"å¹³å‡ {total_elapsed/TOTAL_REQUESTS:.2f}s/æ¬¡\")\n",
    "\n",
    "\n",
    "def stop_containers():\n",
    "    client = docker.from_env()\n",
    "    for i in range(INSTANCE_COUNT):\n",
    "        name = f\"vllm_cpu_{BASE_PORT + i}\"\n",
    "        try:\n",
    "            cont = client.containers.get(name)\n",
    "            cont.remove(force=True)\n",
    "            print(f\"[âœ“] å·²ç§»é™¤å®¹å™¨ {name}\")\n",
    "        except NotFound:\n",
    "            print(f\"[!] å®¹å™¨ {name} ä¸å­˜åœ¨æˆ–å·²è¢«ç§»é™¤\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        start_containers()\n",
    "        benchmark_all()\n",
    "    finally:\n",
    "        print(\"\\n[*] æ¸…ç†ï¼šåœæ­¢å¹¶ç§»é™¤æ‰€æœ‰å®¹å™¨â€¦\")\n",
    "        stop_containers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f538f3c6-20b1-4b4e-a2fa-8580efea9d26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        return number % 1.0;\n"
     ]
    }
   ],
   "source": [
    "def extract_indented_body(code: str) -> str:\n",
    "    \"\"\"æå– Python æˆ– Java çš„ä»£ç ä¸»ä½“\"\"\"\n",
    "    lines = code.splitlines()\n",
    "    # Python å‡½æ•°ä½“æå–\n",
    "    if any(ln.startswith(\"def \") for ln in lines):\n",
    "        saw = False\n",
    "        out = []\n",
    "        for ln in lines:\n",
    "            if not saw:\n",
    "                if ln.startswith(\"def \"):\n",
    "                    saw = True\n",
    "                continue\n",
    "            out.append(ln)\n",
    "        return \"\\n\".join(out).rstrip()\n",
    "    # Java æ–¹æ³•ä½“æå–\n",
    "    if any(ln.strip().startswith((\"public \", \"private \", \"protected \")) for ln in lines):\n",
    "        start_idx = None\n",
    "        # å¯»æ‰¾æ–¹æ³•ç­¾ååçš„ç¬¬ä¸€è¡Œ '{' ä¹‹åçš„å†…å®¹\n",
    "        for i, ln in enumerate(lines):\n",
    "            if \"{\" in ln:\n",
    "                start_idx = i + 1\n",
    "                break\n",
    "        # å¯»æ‰¾æœ€åä¸€ä¸ª '}' çš„è¡Œ\n",
    "        end_idx = None\n",
    "        for j in range(len(lines) - 1, -1, -1):\n",
    "            if \"}\" in lines[j]:\n",
    "                end_idx = j\n",
    "                break\n",
    "        if start_idx is not None and end_idx is not None and start_idx < end_idx:\n",
    "            return \"\\n\".join(lines[start_idx:end_idx]).rstrip()\n",
    "    # é»˜è®¤æŒ‰ç¼©è¿›æå–\n",
    "    return \"\\n\".join([ln for ln in lines if ln.startswith(\"    \") or ln.startswith(\"\\t\")]).rstrip()\n",
    "# ------------------------ æµ‹è¯• extract_indented_body ------------------------ #\n",
    "def test_extract_java():\n",
    "    java_code = \"        return number % 1.0;\"\n",
    "    body = extract_indented_body(java_code)\n",
    "    if \") {\\n\" in body:\n",
    "        print(\"Java code detected, extracting method body...\")\n",
    "        body = extract_indented_body(body)\n",
    "    print(body)\n",
    "test_extract_java()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda] *",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
