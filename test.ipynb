{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ca968ce-84dd-4beb-97bd-51b2d936d195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output:\n",
      "  city that is known for its unique architecture, vibrant culture, and stunning natural beauty. It is also a city that is home to some of the most iconic landmarks in the world, including the Golden Gate Bridge, the Golden Gate Park, and the Golden Gate Bridge Museum. The city is also home to some of the most famous museums in the world, including the Museum of Modern Art, the San Francisco Museum of Modern Art, and the Museum of the Moving Image.\n",
      "San Francisco is also home to some\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def call_qwen2(prompt: str, max_tokens: int = 100, temperature: float = 0.0):\n",
    "    url = \"http://localhost:8000/v1/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"/models/qwen2\",\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature\n",
    "    }\n",
    "\n",
    "    resp = requests.post(url, json=payload, headers=headers)\n",
    "    resp.raise_for_status()  # 如果返回码不是 2xx，会抛出异常\n",
    "\n",
    "    data = resp.json()\n",
    "    # 通常生成结果在 data[\"choices\"][0][\"text\"]\n",
    "    return data[\"choices\"][0][\"text\"]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    output = call_qwen2(\"San Francisco is a\")\n",
    "    print(\"Model output:\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b8915fa-1744-41a0-8940-2fb752f21748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "Body: {\"id\":\"chatcmpl-68d58d5f802f4761b71717919a984763\",\"object\":\"chat.completion\",\"created\":1745005422,\"model\":\"/models/qwen2\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"reasoning_content\":null,\"content\":\"The 2020 World Series was won by the Los Angeles Dodgers, led by Clayton Kershaw and Clayton Kershaw.\",\"tool_calls\":[]},\"logprobs\":null,\"finish_reason\":\"stop\",\"stop_reason\":null}],\"usage\":{\"prompt_tokens\":31,\"total_tokens\":60,\"completion_tokens\":29,\"prompt_tokens_details\":null},\"prompt_logprobs\":null}\n",
      "Reply: The 2020 World Series was won by the Los Angeles Dodgers, led by Clayton Kershaw and Clayton Kershaw.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def chat_with_model(messages, model=\"/models/qwen2\"):\n",
    "    url = \"http://localhost:8000/v1/chat/completions\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 128,       # 一定要带上 max_tokens\n",
    "        \"temperature\": 0.0       # 建议带上 temperature\n",
    "    }\n",
    "    resp = requests.post(url, json=payload, headers=headers)\n",
    "    print(\"Status:\", resp.status_code)\n",
    "    print(\"Body:\", resp.text)  # 先看看服务器到底怎么说\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    msgs = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",   \"content\": \"Who won the world series in 2020?\"}\n",
    "    ]\n",
    "    try:\n",
    "        result = chat_with_model(msgs)\n",
    "        print(\"Reply:\", result[\"choices\"][0][\"message\"][\"content\"])\n",
    "    except Exception as e:\n",
    "        print(\"调用失败\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1bb74c76-9407-4d1a-a2ff-23d08bb410bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'cmpl-5761d103a2ce4bb885040d7d5c641d68',\n",
      " 'object': 'text_completion',\n",
      " 'created': 1745004218,\n",
      " 'model': '/models/qwen2',\n",
      " 'choices': [{'index': 0,\n",
      "              'text': '\\n'\n",
      "                      'What is the current time in the format \"HH:MM:SS\"?\\n'\n",
      "                      'To find the current time in the format \"HH:MM:SS\", you '\n",
      "                      'can use the following Python code:\\n'\n",
      "                      '```python\\n'\n",
      "                      'import datetime\\n'\n",
      "                      'current_time = datetime.datetime.now().time()\\n'\n",
      "                      'current_time\\n'\n",
      "                      '```\\n'\n",
      "                      'This will output the',\n",
      "              'logprobs': None,\n",
      "              'finish_reason': 'length',\n",
      "              'stop_reason': None,\n",
      "              'prompt_logprobs': None}],\n",
      " 'usage': {'prompt_tokens': 32, 'total_tokens': 96, 'completion_tokens': 64}}\n"
     ]
    }
   ],
   "source": [
    "import requests, pprint\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_completion(prompt, host=\"localhost\", port=8000,\n",
    "                        max_tokens=64, temperature=0.2):\n",
    "    url = f\"http://{host}:{port}/v1/completions\"\n",
    "    payload = {\"model\": \"/models/qwen2\",\n",
    "               \"prompt\": prompt,\n",
    "               \"max_tokens\": max_tokens,\n",
    "               \"temperature\": temperature}\n",
    "    r = requests.post(url, json=payload, timeout=600)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "resp = generate_completion(f\"What time is it? {datetime.now()}\")\n",
    "pprint.pp(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5dbd04-5e81-4e13-98d2-b6e17a445d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda] *",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
